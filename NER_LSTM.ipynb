{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r6YTnpgbFdMI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162.22s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 10 17:44:04 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.12              Driver Version: 550.90.12      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  |   00000000:1A:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             40W /  300W |       1MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           On  |   00000000:1C:00.0 Off |                    0 |\n",
      "| N/A   27C    P0             40W /  300W |       1MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-32GB           On  |   00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   25C    P0             39W /  300W |       1MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-32GB           On  |   00000000:1E:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             41W /  300W |       1MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==2.2.0 torchtext==0.17.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install -U scikit-learn\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EjRM4cCFRh-d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.vocab import Vocab, vocab\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict, Optional, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yn1bIPjAN-9V"
   },
   "source": [
    "## Long Short Term Memory (LSTM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJOKIneRTrTH"
   },
   "source": [
    "### Data Loading\n",
    "\n",
    "We will use the same dataset for named entity recognition in Assignment #2. First download the data and take a look at the first 50 lines:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVt1a6nzWsiF"
   },
   "source": [
    "Each line corresponds to a word. Different sentences are separated by an additional line break. Take \"EU NNP I-NP ORG\" as an example. \"EU\" is a word. \"NNP\" and \"I-NP\" are tags for POS tagging and chunking, which we will ignore. \"ORG\" is the tag for NER, which is our prediction target. There are 5 possible values for the NER tag: ORG, PER, LOC, MISC, and O.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WnNfOBUYJvVW"
   },
   "outputs": [],
   "source": [
    "# A sentence is a list of (word, tag) tuples.\n",
    "# For example, [(\"hello\", \"O\"), (\"world\", \"O\"), (\"!\", \"O\")]\n",
    "Sentence = List[Tuple[str, str]]\n",
    "\n",
    "\n",
    "def read_data_file(\n",
    "    datapath: str,\n",
    ") -> Tuple[List[Sentence], Dict[str, int], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Read and preprocess input data from the file `datapath`.\n",
    "    Example:\n",
    "    ```\n",
    "        sentences, word_cnt, tag_cnt = read_data_file(\"eng.train\")\n",
    "    ```\n",
    "    Return values:\n",
    "        `sentences`: a list of sentences, including words and NER tags\n",
    "        `word_cnt`: a Counter object, the number of occurrences of each word\n",
    "        `tag_cnt`: a Counter object, the number of occurences of each NER tag\n",
    "    \"\"\"\n",
    "    sentences: List[Sentence] = []\n",
    "    word_cnt: Dict[str, int] = Counter()\n",
    "    tag_cnt: Dict[str, int] = Counter()\n",
    "\n",
    "    for sentence_txt in open(datapath).read().split(\"\\n\\n\"):\n",
    "        if \"DOCSTART\" in sentence_txt:\n",
    "            # Ignore dummy sentences at the begining of each document.\n",
    "            continue\n",
    "        # Read a new sentence\n",
    "        sentences.append([])\n",
    "        for token in sentence_txt.split(\"\\n\"):\n",
    "            w, _, _, t = token.split()\n",
    "            # Replace all digits with \"0\" to reduce out-of-vocabulary words\n",
    "            w = re.sub(\"\\d\", \"0\", w)\n",
    "            word_cnt[w] += 1\n",
    "            tag_cnt[t] += 1\n",
    "            sentences[-1].append((w, t))\n",
    "\n",
    "    return sentences, word_cnt, tag_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WLMGYSZ7KxzP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Some helper code\n",
    "def get_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Use GPU when it is available; use CPU otherwise.\n",
    "    \"\"\"\n",
    "    return torch.device(\"gpu\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "print(get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wVHAOb7iMPwC"
   },
   "outputs": [],
   "source": [
    "def eval_metrics(ground_truth: List[int], predictions: List[int]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calculate various evaluation metrics such as accuracy and F1 score\n",
    "    Parameters:\n",
    "        `ground_truth`: the list of ground truth NER tags\n",
    "        `predictions`: the list of predicted NER tags\n",
    "    \"\"\"\n",
    "    f1_scores = f1_score(ground_truth, predictions, average=None)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(ground_truth, predictions),\n",
    "        \"average f1\": np.mean(f1_scores),\n",
    "        \"f1\": f1_scores,\n",
    "        \"confusion matrix\": confusion_matrix(ground_truth, predictions),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7s830dhbnj1L"
   },
   "source": [
    "## Long Short-term Memory (LSTM)\n",
    "\n",
    "Now we implement an one-layer LSTM for the same task and compare it to FFNNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "to7DnWNiY5ZS"
   },
   "source": [
    "### Data Loading **(4 points)**\n",
    "\n",
    "Like before, we first implement the data loader. But unlike before, each data example is now a variable-length sentence. How can we pack multiple sentences with different lengths into the same batch? One possible solution is to pad them to the same length using a special token.\n",
    "\n",
    "> Padding ensures that all sentences in the batch have the same length, making it possible to process them simultaneously in a neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "J5oVgqE7JaJp"
   },
   "outputs": [],
   "source": [
    "# 3 sentences with different lengths\n",
    "sentence_1 = torch.tensor([6, 1, 2])\n",
    "sentence_2 = torch.tensor([4, 2, 7, 7, 9])\n",
    "sentence_3 = torch.tensor([3, 4])\n",
    "# Form a batch by padding 0\n",
    "sentence_batch = torch.tensor(\n",
    "    [\n",
    "        [6, 1, 2, 0, 0],\n",
    "        [4, 2, 7, 7, 9],\n",
    "        [3, 4, 0, 0, 0],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udC0SMjkKaCN"
   },
   "source": [
    "We implement the above idea in a customized batching function `form_batch`. Optionally, see [here](https://pytorch.org/docs/stable/data.html#loading-batched-and-non-batched-data) for how batching works in PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sACcGN4XYMgj"
   },
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each data example is a sentence, including its words and NER tags.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        datapath: str,\n",
    "        words_vocab: Optional[Vocab] = None,\n",
    "        tags_vocab: Optional[Vocab] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the dataset by reading from datapath.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.sentences: List[Sentence] = []\n",
    "        UNKNOWN = \"<UNKNOWN>\"\n",
    "        PAD = \"<PAD>\"  # Special token used for padding\n",
    "\n",
    "        print(\"Loading data from %s\" % datapath)\n",
    "        self.sentences, word_cnt, tag_cnt = read_data_file(datapath)\n",
    "        print(\"%d sentences loaded.\" % len(self.sentences))\n",
    "\n",
    "        if words_vocab is None:\n",
    "            words_vocab = vocab(word_cnt, specials=[PAD, UNKNOWN])\n",
    "            words_vocab.set_default_index(words_vocab[UNKNOWN])\n",
    "\n",
    "        self.words_vocab = words_vocab\n",
    "\n",
    "        self.unknown_idx = self.words_vocab[UNKNOWN]\n",
    "        self.pad_idx = self.words_vocab[PAD]\n",
    "\n",
    "        if tags_vocab is None:\n",
    "            tags_vocab = vocab(tag_cnt, specials=[])\n",
    "        self.tags_vocab = tags_vocab\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Sentence:\n",
    "        \"\"\"\n",
    "        Get the idx'th sentence in the dataset.\n",
    "        \"\"\"\n",
    "        return self.sentences[idx]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Return the number of sentences in the dataset.\n",
    "        \"\"\"\n",
    "        # TODO: Implement this method\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def form_batch(self, sentences: List[Sentence]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        A customized function for batching a number of sentences together.\n",
    "        Different sentences have different lengths. Let max_len be the longest length.\n",
    "        When packing them into one tensor, we need to pad all sentences to max_len.\n",
    "        Return values:\n",
    "            `words`: a list in which each element itself is a list of words in a sentence\n",
    "            `word_idxs`: a batch_size x max_len tensor.\n",
    "                       word_idxs[i][j] is the index of the j'th word in the i'th sentence .\n",
    "            `tags`: a list in which each element itself is a list of tags in a sentence\n",
    "            `tag_idxs`: a batch_size x max_len tensor\n",
    "                      tag_idxs[i][j] is the index of the j'th tag in the i'th sentence.\n",
    "            `valid_mask`: a batch_size x max_len tensor\n",
    "                        valid_mask[i][j] is True if the i'th sentence has the j'th word.\n",
    "                        Otherwise, valid[i][j] is False.\n",
    "        \"\"\"\n",
    "        words: List[List[str]] = []\n",
    "        tags: List[List[str]] = []\n",
    "        max_len = -1  # length of the longest sentence\n",
    "        for sent in sentences:\n",
    "            words.append([])\n",
    "            tags.append([])\n",
    "            for w, t in sent:\n",
    "                words[-1].append(w)\n",
    "                tags[-1].append(t)\n",
    "            max_len = max(max_len, len(words[-1]))\n",
    "\n",
    "        batch_size = len(sentences)\n",
    "        word_idxs = torch.full(\n",
    "            (batch_size, max_len), fill_value=self.pad_idx, dtype=torch.int64\n",
    "        )\n",
    "        tag_idxs = torch.full_like(word_idxs, fill_value=self.tags_vocab[\"O\"])\n",
    "        valid_mask = torch.zeros_like(word_idxs, dtype=torch.bool)\n",
    "\n",
    "        ## TODO: Fill in the values in word_idxs, tag_idxs, and valid_mask\n",
    "        ## Caveat: There may be out-of-vocabulary words in validation data\n",
    "        ## See torchtext.vocab.Vocab: https://pytorch.org/text/stable/vocab.html#torchtext.vocab.Vocab\n",
    "\n",
    "        for i, (w, t) in enumerate(zip(words, tags)):\n",
    "            for j, (word, tag) in enumerate(zip(w, t)):\n",
    "                word_idxs[i][j] = self.words_vocab[word]\n",
    "                tag_idxs[i][j] = self.tags_vocab[tag]\n",
    "                valid_mask[i][j] = True\n",
    "\n",
    "        return {\n",
    "            \"words\": words,\n",
    "            \"word_idxs\": word_idxs,\n",
    "            \"tags\": tags,\n",
    "            \"tag_idxs\": tag_idxs,\n",
    "            \"valid_mask\": valid_mask,\n",
    "        }\n",
    "\n",
    "\n",
    "def create_sequence_dataloaders(\n",
    "    batch_size: int, shuffle: bool = True\n",
    ") -> Tuple[DataLoader, DataLoader, Vocab]:\n",
    "    \"\"\"\n",
    "    Create the dataloaders for training and validaiton.\n",
    "    \"\"\"\n",
    "    ds_train = SequenceDataset(\"eng.train\")\n",
    "    ds_val = SequenceDataset(\n",
    "        \"eng.val\", words_vocab=ds_train.words_vocab, tags_vocab=ds_train.tags_vocab\n",
    "    )\n",
    "    loader_train = DataLoader(\n",
    "        ds_train,\n",
    "        batch_size,\n",
    "        shuffle,\n",
    "        collate_fn=ds_train.form_batch,  # customized function for batching\n",
    "        drop_last=True,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    loader_val = DataLoader(\n",
    "        ds_val, batch_size, collate_fn=ds_val.form_batch, pin_memory=True\n",
    "    )\n",
    "    return loader_train, loader_val, ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2EcVxYuYvGv"
   },
   "source": [
    "Here is a simple sanity-check. Try to understand its output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TazmodGWYx2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from eng.train\n",
      "14041 sentences loaded.\n",
      "Loading data from eng.val\n",
      "3490 sentences loaded.\n",
      "Iterating on the training data..\n",
      "{'words': [['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], ['Peter', 'Blackburn'], ['BRUSSELS', '0000-00-00']], 'word_idxs': tensor([[ 2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [11, 12,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [13, 14,  0,  0,  0,  0,  0,  0,  0]]), 'tags': [['ORG', 'O', 'MISC', 'O', 'O', 'O', 'MISC', 'O', 'O'], ['PER', 'PER'], ['LOC', 'O']], 'tag_idxs': tensor([[0, 1, 2, 1, 1, 1, 2, 1, 1],\n",
      "        [3, 3, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [4, 1, 1, 1, 1, 1, 1, 1, 1]]), 'valid_mask': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True, False, False, False, False, False, False, False],\n",
      "        [ True,  True, False, False, False, False, False, False, False]])}\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def check_sequence_dataloader() -> None:\n",
    "    loader_train, _, _ = create_sequence_dataloaders(batch_size=3, shuffle=False)\n",
    "    print(\"Iterating on the training data..\")\n",
    "    for i, data_batch in enumerate(loader_train):\n",
    "        if i == 0:\n",
    "            print(data_batch)\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "check_sequence_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifk3i-obY8YB"
   },
   "source": [
    "### Implement the Model **(8 points)**\n",
    "\n",
    "Next, implement LSTM for predicting NER tags from input words. [nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM) is definitely useful. Further, it is tricky to handle sentences in the same batch with different lengths. Please read the PyTorch documentation in detail!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3V0NvQynZF8e"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Long short-term memory for NER\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        words_vocab: Vocab,\n",
    "        tags_vocab: Vocab,\n",
    "        d_emb: int,\n",
    "        d_hidden: int,\n",
    "        bidirectional: bool,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize an LSTM\n",
    "        Parameters:\n",
    "            `words_vocab`: vocabulary of words\n",
    "            `tags_vocab`: vocabulary of tags\n",
    "            `d_emb`: dimension of word embeddings (D)\n",
    "            `d_hidden`: dimension of the hidden layer (H)\n",
    "            `bidirectional`: true if LSTM should be bidirectional\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # TODO: Create the word embeddings (nn.Embedding),\n",
    "        #       the LSTM (nn.LSTM) and the output layer (nn.Linear).\n",
    "        #       Read the torch docs for additional guidance : https://pytorch.org/docs/stable\n",
    "        #       Note: Pay attention to the LSTM output shapes!\n",
    "\n",
    "        self.words_vocab = words_vocab\n",
    "        self.tags_vocab = tags_vocab\n",
    "        self.d_emb = d_emb\n",
    "        self.d_hidden = d_hidden\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.embedding = nn.Embedding(len(words_vocab), d_emb)\n",
    "        self.lstm = nn.LSTM(\n",
    "            d_emb, d_hidden, bidirectional=bidirectional, batch_first=True\n",
    "        )\n",
    "        self.output = nn.Linear(\n",
    "            d_hidden * 2 if bidirectional else d_hidden, len(tags_vocab)\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, word_idxs: torch.Tensor, valid_mask: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Given words in sentences, predict the logits of the NER tag.\n",
    "        Parameters:\n",
    "            `word_idxs`: a batch_size x max_len tensor\n",
    "            `valid_mask`: a batch_size x max_len tensor\n",
    "        Return values:\n",
    "            `logits`: a batch_size x max_len x 5 tensor\n",
    "        \"\"\"\n",
    "        # TODO: Implement the forward pass\n",
    "\n",
    "        context_emb = self.embedding(word_idxs)\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(\n",
    "            context_emb, valid_mask.sum(dim=1), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        logits = self.output(lstm_out)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BFTKaB4Zydx"
   },
   "source": [
    "We do a sanity-check by loading a batch of data examples and pass it through the network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The **valid_mask** is used to indicate which positions in the input sequences are valid (i.e., correspond to actual words) and which are padding. <br> This is important for sequence models like LSTMs because padding tokens should not contribute to the model's predictions or loss calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PKg1ni4QZ6D1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from eng.train\n",
      "14041 sentences loaded.\n",
      "Loading data from eng.val\n",
      "3490 sentences loaded.\n",
      "LSTM(\n",
      "  (words_vocab): Vocab()\n",
      "  (tags_vocab): Vocab()\n",
      "  (embedding): Embedding(20102, 64)\n",
      "  (lstm): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
      "  (output): Linear(in_features=256, out_features=5, bias=True)\n",
      ")\n",
      "Input word_idxs shape: torch.Size([4, 20])\n",
      "Input valid_mask shape: torch.Size([4, 20])\n",
      "Output logits shape: torch.Size([4, 20, 5])\n"
     ]
    }
   ],
   "source": [
    "def check_lstm() -> None:\n",
    "    # Hyperparameters\n",
    "    batch_size = 4\n",
    "    d_emb = 64\n",
    "    d_hidden = 128\n",
    "    bidirectional = True\n",
    "    # Create the dataloaders and the model\n",
    "    loader_train, _, ds_train = create_sequence_dataloaders(batch_size)\n",
    "    model = LSTM(\n",
    "        ds_train.words_vocab, ds_train.tags_vocab, d_emb, d_hidden, bidirectional\n",
    "    )\n",
    "    device = get_device()\n",
    "    model.to(device)\n",
    "    print(model)\n",
    "    # Get the first batch\n",
    "    data_batch = next(iter(loader_train))\n",
    "    # Move data to GPU\n",
    "    word_idxs = data_batch[\"word_idxs\"].to(device, non_blocking=True)\n",
    "    tag_idxs = data_batch[\"tag_idxs\"].to(device, non_blocking=True)\n",
    "    valid_mask = data_batch[\"valid_mask\"].to(device, non_blocking=True)\n",
    "    # Calculate the model\n",
    "    print(\"Input word_idxs shape:\", word_idxs.size())\n",
    "    print(\"Input valid_mask shape:\", valid_mask.size())\n",
    "    logits = model(word_idxs, valid_mask)\n",
    "    print(\"Output logits shape:\", logits.size())\n",
    "\n",
    "\n",
    "check_lstm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jddDYUiLY-hc"
   },
   "source": [
    "### Training and Validation **(6 points)**\n",
    "\n",
    "Complete the functions for training and validating the LSTM model. When calculating the loss function, you only want to include values from valid positions (where `valid_mask` is `True`). The `reduction` parameter in [F.cross_entropy](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.cross_entropy) may be useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "hv_15mnXZ_dy"
   },
   "outputs": [],
   "source": [
    "def train_lstm(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    silent: bool = False,  # whether to print the training loss\n",
    ") -> Tuple[float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Train the LSTM model.\n",
    "    Return values:\n",
    "        1. the average training loss\n",
    "        2. training metrics such as accuracy and F1 score\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "    losses = []\n",
    "    report_interval = 100\n",
    "\n",
    "    for i, data_batch in enumerate(loader):\n",
    "        word_idxs = data_batch[\"word_idxs\"].to(device, non_blocking=True)\n",
    "        tag_idxs = data_batch[\"tag_idxs\"].to(device, non_blocking=True)\n",
    "        valid_mask = data_batch[\"valid_mask\"].to(device, non_blocking=True)\n",
    "\n",
    "        # TODO: Do the same tasks as train_ffnn\n",
    "        logits = model(word_idxs, valid_mask)\n",
    "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), tag_idxs.view(-1), ignore_index=-1, reduction='mean')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # we get (unmasked) predictions by getting argmax of logits along last dimension (You will need to define logits!)\n",
    "        net_predictions = torch.argmax(logits, -1)\n",
    "\n",
    "        # flattening a tensor simply converts it from a multi-dimensional to a single-dimensional tensor; we flatten here to make it easier to extract ground truths and predictions\n",
    "        tag_idxs_flat = tag_idxs.flatten()\n",
    "        valid_mask_flat = valid_mask.flatten()\n",
    "        net_predictions_flat = net_predictions.flatten()\n",
    "\n",
    "        ground_truth.extend(tag_idxs_flat[valid_mask_flat].tolist())\n",
    "        predictions.extend(net_predictions_flat[valid_mask_flat].tolist())\n",
    "\n",
    "        if not silent and i > 0 and i % report_interval == 0:\n",
    "            print(\n",
    "                \"\\t[%06d/%06d] Loss: %f\"\n",
    "                % (i, len(loader), np.mean(losses[-report_interval:]))\n",
    "            )\n",
    "\n",
    "    return np.mean(losses), eval_metrics(ground_truth, predictions)\n",
    "\n",
    "\n",
    "def validate_lstm(\n",
    "    model: nn.Module, loader: DataLoader, device: torch.device\n",
    ") -> Tuple[float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Validate the model.\n",
    "    Return the validation loss and metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data_batch in loader:\n",
    "            word_idxs = data_batch[\"word_idxs\"].to(device, non_blocking=True)\n",
    "            tag_idxs = data_batch[\"tag_idxs\"].to(device, non_blocking=True)\n",
    "            valid_mask = data_batch[\"valid_mask\"].to(device, non_blocking=True)\n",
    "\n",
    "            # TODO: Do the same tasks as validate_ffnn\n",
    "            logits = model(word_idxs, valid_mask)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), tag_idxs.view(-1), ignore_index=-1, reduction='mean')\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # we get (unmasked) predictions by getting argmax of logits (You will need to define logits!)\n",
    "            net_predictions = torch.argmax(logits, -1)\n",
    "\n",
    "            # flattening a tensor simply converts it from a multi-dimensional to a single-dimensional tensor; we flatten here to make it easier to extract ground truths and predictions\n",
    "            tag_idxs_flat = tag_idxs.flatten()\n",
    "            valid_mask_flat = valid_mask.flatten()\n",
    "            net_predictions_flat = net_predictions.flatten()\n",
    "\n",
    "            ground_truth.extend(tag_idxs_flat[valid_mask_flat].tolist())\n",
    "            predictions.extend(net_predictions_flat[valid_mask_flat].tolist())\n",
    "\n",
    "    return np.mean(losses), eval_metrics(ground_truth, predictions)\n",
    "\n",
    "\n",
    "def train_val_loop_lstm(hyperparams: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Train and validate the LSTM model for a number of epochs.\n",
    "    \"\"\"\n",
    "    print(\"Hyperparameters:\", hyperparams)\n",
    "    # Create the dataloaders\n",
    "    loader_train, loader_val, ds_train = create_sequence_dataloaders(\n",
    "        hyperparams[\"batch_size\"]\n",
    "    )\n",
    "    # Create the model\n",
    "    model = LSTM(\n",
    "        ds_train.words_vocab,\n",
    "        ds_train.tags_vocab,\n",
    "        hyperparams[\"d_emb\"],\n",
    "        hyperparams[\"d_hidden\"],\n",
    "        hyperparams[\"bidirectional\"],\n",
    "    )\n",
    "    device = get_device()\n",
    "    model.to(device)\n",
    "    print(model)\n",
    "    # Create the optimizer\n",
    "    optimizer = optim.RMSprop(\n",
    "        model.parameters(), hyperparams[\"learning_rate\"], weight_decay=hyperparams[\"l2\"]\n",
    "    )\n",
    "\n",
    "    # Train and validate\n",
    "    for i in range(hyperparams[\"num_epochs\"]):\n",
    "        print(\"*\" * 80)\n",
    "        print(f\"Epoch #{i+1}\")\n",
    "\n",
    "        print(\"Training..\")\n",
    "        loss_train, metrics_train = train_lstm(model, loader_train, optimizer, device)\n",
    "        print(\"Training loss: \", loss_train)\n",
    "        print(\"Training metrics:\")\n",
    "        for k, v in metrics_train.items():\n",
    "            print(\"\\t\", k, \": \", v)\n",
    "\n",
    "        print(\"Validating..\")\n",
    "        loss_val, metrics_val = validate_lstm(model, loader_val, device)\n",
    "        print(\"Validation loss: \", loss_val)\n",
    "        print(\"Validation metrics:\")\n",
    "        for k, v in metrics_val.items():\n",
    "            print(\"\\t\", k, \": \", v)\n",
    "\n",
    "    print(\"************ Training Done! ************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rU9Nef7yal_M"
   },
   "source": [
    "Run the experiment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pFxQxlokai6Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: {'bidirectional': True, 'batch_size': 512, 'd_emb': 64, 'd_hidden': 128, 'num_epochs': 15, 'learning_rate': 0.005, 'l2': 1e-06}\n",
      "Loading data from eng.train\n",
      "14041 sentences loaded.\n",
      "Loading data from eng.val\n",
      "3490 sentences loaded.\n",
      "LSTM(\n",
      "  (words_vocab): Vocab()\n",
      "  (tags_vocab): Vocab()\n",
      "  (embedding): Embedding(20102, 64)\n",
      "  (lstm): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
      "  (output): Linear(in_features=256, out_features=5, bias=True)\n",
      ")\n",
      "********************************************************************************\n",
      "Epoch #1\n",
      "Training..\n",
      "Training loss:  1.0985378269796018\n",
      "Training metrics:\n",
      "\t accuracy :  0.8017554615189079\n",
      "\t average f1 :  0.3318232403255778\n",
      "\t f1 :  [0.19571409 0.89244979 0.04499586 0.26417311 0.26178334]\n",
      "\t confusion matrix :  [[  1443   7565     88    459    272]\n",
      " [  2933 154886   1169   5748   2462]\n",
      " [   122   3888    136    199    175]\n",
      " [   252   7722     75   2698    188]\n",
      " [   169   5844     57    387   1694]]\n",
      "Validating..\n",
      "Validation loss:  0.8370926124708993\n",
      "Validation metrics:\n",
      "\t accuracy :  0.8990343478792324\n",
      "\t average f1 :  0.5712060143871016\n",
      "\t f1 :  [0.46417445 0.95045045 0.22945205 0.60036248 0.61159063]\n",
      "\t confusion matrix :  [[  745  1237    14   140   114]\n",
      " [   53 40934    12   118    47]\n",
      " [   64   717   134    32    60]\n",
      " [   37  1272     0  1325    56]\n",
      " [   61   812     1   109   992]]\n",
      "********************************************************************************\n",
      "Epoch #2\n",
      "Training..\n",
      "Training loss:  0.7132528291808234\n",
      "Training metrics:\n",
      "\t accuracy :  0.9258856238675445\n",
      "\t average f1 :  0.7221973362587526\n",
      "\t f1 :  [0.62385768 0.96787903 0.55552317 0.7278127  0.73591409]\n",
      "\t confusion matrix :  [[  5120   3293    202    671    575]\n",
      " [   323 165562     99    625    250]\n",
      " [   422   1679   1906    217    286]\n",
      " [   355   2952     26   7352    267]\n",
      " [   333   1768    119    386   5551]]\n",
      "Validating..\n",
      "Validation loss:  0.6359798227037702\n",
      "Validation metrics:\n",
      "\t accuracy :  0.932139510247321\n",
      "\t average f1 :  0.7523831065393243\n",
      "\t f1 :  [0.66079295 0.96810232 0.63956964 0.70342293 0.7900277 ]\n",
      "\t confusion matrix :  [[ 1275   746    53    60   116]\n",
      " [   88 40988    36    27    25]\n",
      " [   54   383   535    15    20]\n",
      " [   81  1025     5  1531    48]\n",
      " [  111   371    37    30  1426]]\n",
      "********************************************************************************\n",
      "Epoch #3\n",
      "Training..\n",
      "Training loss:  0.5435905037102876\n",
      "Training metrics:\n",
      "\t accuracy :  0.9628739888656854\n",
      "\t average f1 :  0.8598888169410073\n",
      "\t f1 :  [0.80686832 0.98656659 0.76885406 0.87670463 0.86045048]\n",
      "\t confusion matrix :  [[  7589   1245    214    385    415]\n",
      " [   330 166271    110    297    145]\n",
      " [   358    731   3140    134    167]\n",
      " [   327   1050     50   9354    154]\n",
      " [   359    620    124    234   6838]]\n",
      "Validating..\n",
      "Validation loss:  0.5114131612437112\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9456871613087234\n",
      "\t average f1 :  0.8097087383156211\n",
      "\t f1 :  [0.73576424 0.974412   0.72950363 0.77199202 0.83687181]\n",
      "\t confusion matrix :  [[ 1473   593    51    32   101]\n",
      " [   79 40994    41    22    28]\n",
      " [   39   288   654     8    18]\n",
      " [   59   835    12  1742    42]\n",
      " [  104   267    28    19  1557]]\n",
      "********************************************************************************\n",
      "Epoch #4\n",
      "Training..\n",
      "Training loss:  0.430690034672066\n",
      "Training metrics:\n",
      "\t accuracy :  0.9797631218052612\n",
      "\t average f1 :  0.9211830179480307\n",
      "\t f1 :  [0.89184572 0.99328131 0.86088686 0.94189687 0.91800434]\n",
      "\t confusion matrix :  [[  8613    606    163    210    260]\n",
      " [   195 166540     71    129     81]\n",
      " [   212    448   3679     67    114]\n",
      " [   183    411     40  10229     92]\n",
      " [   260    312     74    130   7406]]\n",
      "Validating..\n",
      "Validation loss:  0.4258976493562971\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9519414904453408\n",
      "\t average f1 :  0.8340599869738439\n",
      "\t f1 :  [0.76783079 0.97716601 0.75660793 0.80927292 0.85942228]\n",
      "\t confusion matrix :  [[ 1561   530    43    55    61]\n",
      " [   75 40997    40    40    12]\n",
      " [   34   268   687     9     9]\n",
      " [   33   709    12  1920    16]\n",
      " [  113   242    27    31  1562]]\n",
      "********************************************************************************\n",
      "Epoch #5\n",
      "Training..\n",
      "Training loss:  0.3513661567811613\n",
      "Training metrics:\n",
      "\t accuracy :  0.9886869352832761\n",
      "\t average f1 :  0.9548468705254043\n",
      "\t f1 :  [0.93776912 0.99640463 0.91524648 0.97287919 0.95193493]\n",
      "\t confusion matrix :  [[  9147    334     89    115    180]\n",
      " [   136 166420     59     58     42]\n",
      " [   132    259   4001     49     82]\n",
      " [    79    152     23  10654     53]\n",
      " [   149    161     48     65   7724]]\n",
      "Validating..\n",
      "Validation loss:  0.3644140958786011\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9530212280487308\n",
      "\t average f1 :  0.8395446908430928\n",
      "\t f1 :  [0.78232971 0.97755046 0.76833773 0.79470199 0.87480356]\n",
      "\t confusion matrix :  [[ 1585   503    51    17    94]\n",
      " [   69 40997    57    13    28]\n",
      " [   20   238   728     5    16]\n",
      " [   59   764    32  1800    35]\n",
      " [   69   211    20     5  1670]]\n",
      "********************************************************************************\n",
      "Epoch #6\n",
      "Training..\n",
      "Training loss:  0.291213298285449\n",
      "Training metrics:\n",
      "\t accuracy :  0.9934749749325299\n",
      "\t average f1 :  0.9740114916570572\n",
      "\t f1 :  [0.9617941  0.99785467 0.94946988 0.9886789  0.97225989]\n",
      "\t confusion matrix :  [[  9478    220     62     40     98]\n",
      " [   103 166749     33     25     19]\n",
      " [    89    164   4209     15     43]\n",
      " [    29     69      9  10829     28]\n",
      " [   112     84     33     33   7886]]\n",
      "Validating..\n",
      "Validation loss:  0.31870704889297485\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9530212280487308\n",
      "\t average f1 :  0.8370374872615656\n",
      "\t f1 :  [0.74273412 0.97775818 0.7776     0.82350436 0.86359077]\n",
      "\t confusion matrix :  [[ 1380   596    67    35   172]\n",
      " [   38 41015    45    25    41]\n",
      " [    5   239   729     7    27]\n",
      " [   14   675    16  1934    51]\n",
      " [   29   207    11     6  1722]]\n",
      "********************************************************************************\n",
      "Epoch #7\n",
      "Training..\n",
      "Training loss:  0.2454452520167386\n",
      "Training metrics:\n",
      "\t accuracy :  0.9951968397899178\n",
      "\t average f1 :  0.982045585228794\n",
      "\t f1 :  [0.97461981 0.99824636 0.96696358 0.98852877 0.98186941]\n",
      "\t confusion matrix :  [[  9581    138     36     30     83]\n",
      " [    71 166788     28    104     20]\n",
      " [    49    116   4288     16     27]\n",
      " [    20     55      4  10858      9]\n",
      " [    72     54     17     14   8015]]\n",
      "Validating..\n",
      "Validation loss:  0.302959680557251\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9394735769873284\n",
      "\t average f1 :  0.7922613372712702\n",
      "\t f1 :  [0.7503075  0.97110483 0.77877984 0.5915493  0.86956522]\n",
      "\t confusion matrix :  [[ 1525   596    39     6    84]\n",
      " [   60 41052    36     1    15]\n",
      " [   21   241   734     0    11]\n",
      " [  136  1280    54  1134    86]\n",
      " [   73   214    15     3  1670]]\n",
      "********************************************************************************\n",
      "Epoch #8\n",
      "Training..\n",
      "Training loss:  0.2081690905270753\n",
      "Training metrics:\n",
      "\t accuracy :  0.9964685285036636\n",
      "\t average f1 :  0.9870700064242859\n",
      "\t f1 :  [0.9818533  0.99873684 0.97681127 0.98771544 0.99023318]\n",
      "\t confusion matrix :  [[  9658    101     27     32     32]\n",
      " [    52 166830     23     18     11]\n",
      " [    34     76   4402      7     15]\n",
      " [    54    106     18  10774     23]\n",
      " [    25     35      9     10   8111]]\n",
      "Validating..\n",
      "Validation loss:  0.24387473506586893\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9577068817992911\n",
      "\t average f1 :  0.8566003756579381\n",
      "\t f1 :  [0.7803902  0.97951236 0.78961601 0.84553183 0.88795149]\n",
      "\t confusion matrix :  [[ 1560   527    43    42    78]\n",
      " [   67 40997    50    31    19]\n",
      " [   19   233   730     9    16]\n",
      " [   32   589     9  2039    21]\n",
      " [   70   199    10    12  1684]]\n",
      "********************************************************************************\n",
      "Epoch #9\n",
      "Training..\n",
      "Training loss:  0.17663699002177627\n",
      "Training metrics:\n",
      "\t accuracy :  0.9987395690621497\n",
      "\t average f1 :  0.9952225274403597\n",
      "\t f1 :  [0.99280576 0.99950666 0.98978912 0.99835706 0.99565404]\n",
      "\t confusion matrix :  [[  9798     49     13      6     17]\n",
      " [    24 167144     12      5      4]\n",
      " [    15     38   4459      2      7]\n",
      " [     7      9      2  10938      3]\n",
      " [    11     24      3      2   8133]]\n",
      "Validating..\n",
      "Validation loss:  0.2218125398669924\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9573809232775129\n",
      "\t average f1 :  0.8564049415514535\n",
      "\t f1 :  [0.78105316 0.97911894 0.79180151 0.83933054 0.89072055]\n",
      "\t confusion matrix :  [[ 1550   548    43    37    72]\n",
      " [   51 41029    47    25    12]\n",
      " [   18   234   734    10    11]\n",
      " [   30   628    10  2006    16]\n",
      " [   70   205    13    12  1675]]\n",
      "********************************************************************************\n",
      "Epoch #10\n",
      "Training..\n",
      "Training loss:  0.15158800118499333\n",
      "Training metrics:\n",
      "\t accuracy :  0.9990433435144171\n",
      "\t average f1 :  0.9963638595993991\n",
      "\t f1 :  [0.99412361 0.99963511 0.99262033 0.99917868 0.99626157]\n",
      "\t confusion matrix :  [[  9812     40     13      5     10]\n",
      " [    19 167112     10      0      6]\n",
      " [    12     22   4506      1      4]\n",
      " [     6      3      0  10949      2]\n",
      " [    11     22      5      1   8128]]\n",
      "Validating..\n",
      "Validation loss:  0.20109753949301584\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9472558366947806\n",
      "\t average f1 :  0.8183820432099184\n",
      "\t f1 :  [0.70101513 0.97725791 0.70924574 0.84924211 0.85514932]\n",
      "\t confusion matrix :  [[ 1830   344     5    31    40]\n",
      " [  567 40479    39    63    16]\n",
      " [  196   205   583    12    11]\n",
      " [  135   470     3  2073     9]\n",
      " [  243   180     7    13  1532]]\n",
      "********************************************************************************\n",
      "Epoch #11\n",
      "Training..\n",
      "Training loss:  0.1348300912865886\n",
      "Training metrics:\n",
      "\t accuracy :  0.9961352946463345\n",
      "\t average f1 :  0.9845223246010029\n",
      "\t f1 :  [0.96597315 0.9988911  0.97207814 0.99525937 0.99040987]\n",
      "\t confusion matrix :  [[  9425    179    112     59     64]\n",
      " [   102 166647     21      6      7]\n",
      " [    73     35   4404      1      7]\n",
      " [    26      3      0  10917      4]\n",
      " [    49     17      4      5   8107]]\n",
      "Validating..\n",
      "Validation loss:  0.17782072722911835\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9593570468157927\n",
      "\t average f1 :  0.8638377629616393\n",
      "\t f1 :  [0.79358717 0.98020843 0.80512547 0.84745763 0.89281011]\n",
      "\t confusion matrix :  [[ 1584   496    42    48    80]\n",
      " [   63 41008    46    29    18]\n",
      " [   14   222   754     6    11]\n",
      " [   33   579    10  2050    18]\n",
      " [   48   203    14    15  1695]]\n",
      "********************************************************************************\n",
      "Epoch #12\n",
      "Training..\n",
      "Training loss:  0.11382009475319474\n",
      "Training metrics:\n",
      "\t accuracy :  0.9993010100404915\n",
      "\t average f1 :  0.9975546836782796\n",
      "\t f1 :  [0.99544765 0.99970611 0.99547411 0.99922505 0.99792049]\n",
      "\t confusion matrix :  [[  9840     29     12      5      6]\n",
      " [    23 166682      8      2      5]\n",
      " [     5     13   4509      0      2]\n",
      " [     4      5      0  10960      1]\n",
      " [     6     13      1      0   8158]]\n",
      "Validating..\n",
      "Validation loss:  0.16331814229488373\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9607627429409608\n",
      "\t average f1 :  0.8686625187040047\n",
      "\t f1 :  [0.80239521 0.98079015 0.80793991 0.85468334 0.89750398]\n",
      "\t confusion matrix :  [[ 1608   491    38    49    64]\n",
      " [   50 41024    44    32    14]\n",
      " [   15   221   753     7    11]\n",
      " [   31   554     8  2085    12]\n",
      " [   54   201    14    16  1690]]\n",
      "********************************************************************************\n",
      "Epoch #13\n",
      "Training..\n",
      "Training loss:  0.09969751316088217\n",
      "Training metrics:\n",
      "\t accuracy :  0.9996661035278405\n",
      "\t average f1 :  0.9988728223804137\n",
      "\t f1 :  [0.99817998 0.99985338 0.99811509 0.99949888 0.99871677]\n",
      "\t confusion matrix :  [[  9872     14      2      3      0]\n",
      " [     8 167079      0      0      5]\n",
      " [     2     11   4501      0      2]\n",
      " [     5      1      0  10970      1]\n",
      " [     2     10      0      1   8172]]\n",
      "Validating..\n",
      "Validation loss:  0.15319917457444326\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9605590188648494\n",
      "\t average f1 :  0.8680823241942626\n",
      "\t f1 :  [0.79859013 0.98062127 0.81022295 0.85491803 0.89605924]\n",
      "\t confusion matrix :  [[ 1586   504    36    51    73]\n",
      " [   47 41039    37    29    12]\n",
      " [   13   229   745     9    11]\n",
      " [   26   558     4  2086    16]\n",
      " [   50   206    10    15  1694]]\n",
      "********************************************************************************\n",
      "Epoch #14\n",
      "Training..\n",
      "Training loss:  0.08656775841006527\n",
      "Training metrics:\n",
      "\t accuracy :  0.9997310569462015\n",
      "\t average f1 :  0.999013535443592\n",
      "\t f1 :  [0.99888585 0.9998834  0.99779493 0.99954434 0.99895916]\n",
      "\t confusion matrix :  [[  9862      9      2      2      1]\n",
      " [     3 167219      4      1      3]\n",
      " [     0      9   4525      2      2]\n",
      " [     3      2      0  10968      0]\n",
      " [     2      8      1      0   8158]]\n",
      "Validating..\n",
      "Validation loss:  0.13334493339061737\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9600700810821823\n",
      "\t average f1 :  0.8621353431563886\n",
      "\t f1 :  [0.81340181 0.98093579 0.75696822 0.86614173 0.89322917]\n",
      "\t confusion matrix :  [[ 1663   409    58    42    78]\n",
      " [   77 40829   161    55    42]\n",
      " [   12   202   774     8    11]\n",
      " [   34   470    22  2145    19]\n",
      " [   53   171    23    13  1715]]\n",
      "********************************************************************************\n",
      "Epoch #15\n",
      "Training..\n",
      "Training loss:  0.08095126185152265\n",
      "Training metrics:\n",
      "\t accuracy :  0.9941494216755697\n",
      "\t average f1 :  0.9826786001432437\n",
      "\t f1 :  [0.98455793 0.9973705  0.97992056 0.96601188 0.98553212]\n",
      "\t confusion matrix :  [[  9755     74      3     29     25]\n",
      " [    74 166513     53    241     35]\n",
      " [     1     65   4441     14     11]\n",
      " [    65    295     23  10573     35]\n",
      " [    35     41     12     42   8038]]\n",
      "Validating..\n",
      "Validation loss:  0.12015386138643537\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9622906735117956\n",
      "\t average f1 :  0.8736261190205935\n",
      "\t f1 :  [0.81150794 0.98168901 0.81842818 0.86111679 0.89538867]\n",
      "\t confusion matrix :  [[ 1636   462    28    43    81]\n",
      " [   47 41040    37    28    12]\n",
      " [   12   218   755    10    12]\n",
      " [   25   536     8  2105    16]\n",
      " [   62   191    10    13  1699]]\n",
      "************ Training Done! ************\n"
     ]
    }
   ],
   "source": [
    "train_val_loop_lstm(\n",
    "    {\n",
    "        \"bidirectional\": True,\n",
    "        \"batch_size\": 512,\n",
    "        \"d_emb\": 64,\n",
    "        \"d_hidden\": 128,\n",
    "        \"num_epochs\": 15,\n",
    "        \"learning_rate\": 0.005,\n",
    "        \"l2\": 1e-6,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vA-Yjqg7n0V"
   },
   "source": [
    "We were using bidirectional LSTMs. Please re-run the experiment with a regular (unidirectional) LSTM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7wNrdvJ98ARB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: {'bidirectional': False, 'batch_size': 512, 'd_emb': 64, 'd_hidden': 128, 'num_epochs': 15, 'learning_rate': 0.005, 'l2': 1e-06}\n",
      "Loading data from eng.train\n",
      "14041 sentences loaded.\n",
      "Loading data from eng.val\n",
      "3490 sentences loaded.\n",
      "LSTM(\n",
      "  (words_vocab): Vocab()\n",
      "  (tags_vocab): Vocab()\n",
      "  (embedding): Embedding(20102, 64)\n",
      "  (lstm): LSTM(64, 128, batch_first=True)\n",
      "  (output): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n",
      "********************************************************************************\n",
      "Epoch #1\n",
      "Training..\n",
      "Training loss:  1.0759901978351452\n",
      "Training metrics:\n",
      "\t accuracy :  0.8070387199425411\n",
      "\t average f1 :  0.322689427796722\n",
      "\t f1 :  [0.10858011 0.89992691 0.05757488 0.23694338 0.31042187]\n",
      "\t confusion matrix :  [[   715   7542    149    565    914]\n",
      " [  2014 156374   1710   3961   2927]\n",
      " [   152   3503    198    232    430]\n",
      " [   225   7975    165   2155    431]\n",
      " [   179   5146    141    326   2362]]\n",
      "Validating..\n",
      "Validation loss:  0.8399518047060285\n",
      "Validation metrics:\n",
      "\t accuracy :  0.8957747626614513\n",
      "\t average f1 :  0.5446875765726733\n",
      "\t f1 :  [0.30064973 0.95863557 0.21565217 0.63414634 0.61435407]\n",
      "\t confusion matrix :  [[  509  1089    12   240   400]\n",
      " [  222 40441     2   308   191]\n",
      " [  104   468   124   109   202]\n",
      " [  190   760     0  1612   128]\n",
      " [  111   450     5   125  1284]]\n",
      "********************************************************************************\n",
      "Epoch #2\n",
      "Training..\n",
      "Training loss:  0.7203596455079538\n",
      "Training metrics:\n",
      "\t accuracy :  0.9237355794179873\n",
      "\t average f1 :  0.6935589271582092\n",
      "\t f1 :  [0.55991235 0.97325939 0.50572438 0.72068146 0.70821705]\n",
      "\t confusion matrix :  [[  4855   2827    319    761   1083]\n",
      " [   495 165494    138    572    257]\n",
      " [   597   1270   1789    325    558]\n",
      " [   735   2380    160   7276    354]\n",
      " [   815   1155    130    353   5710]]\n",
      "Validating..\n",
      "Validation loss:  0.6422009893826076\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9190604245609746\n",
      "\t average f1 :  0.7198929096371822\n",
      "\t f1 :  [0.53165468 0.97221609 0.60772244 0.75537939 0.73249196]\n",
      "\t confusion matrix :  [[ 1478   304    69   163   236]\n",
      " [  966 39611    77   311   199]\n",
      " [  181   129   543    69    85]\n",
      " [  400   185    38  2001    66]\n",
      " [  285    93    53    64  1480]]\n",
      "********************************************************************************\n",
      "Epoch #3\n",
      "Training..\n",
      "Training loss:  0.5513762301868863\n",
      "Training metrics:\n",
      "\t accuracy :  0.9577730726117822\n",
      "\t average f1 :  0.829944861722806\n",
      "\t f1 :  [0.75174038 0.98786452 0.73095605 0.8653469  0.81381645]\n",
      "\t confusion matrix :  [[  7181   1168    329    494    751]\n",
      " [   391 166225    154    316    130]\n",
      " [   363    583   3085    224    277]\n",
      " [   482    846    156   9267    151]\n",
      " [   765    496    185    215   6491]]\n",
      "Validating..\n",
      "Validation loss:  0.5172167207513537\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9290836491056513\n",
      "\t average f1 :  0.7596865874643398\n",
      "\t f1 :  [0.57582559 0.97590125 0.65984347 0.81197086 0.77489177]\n",
      "\t confusion matrix :  [[ 1796   210    37    90   117]\n",
      " [ 1114 39767    39   158    86]\n",
      " [  237   116   548    43    63]\n",
      " [  430   164    11  2062    23]\n",
      " [  411    77    19    36  1432]]\n",
      "********************************************************************************\n",
      "Epoch #4\n",
      "Training..\n",
      "Training loss:  0.4407909909884135\n",
      "Training metrics:\n",
      "\t accuracy :  0.9742105893866464\n",
      "\t average f1 :  0.890323532922603\n",
      "\t f1 :  [0.83826176 0.99374987 0.81200046 0.93448702 0.87311855]\n",
      "\t confusion matrix :  [[  8150    596    271    305    530]\n",
      " [   255 166231     85    131     73]\n",
      " [   318    359   3505    130    216]\n",
      " [   257    341     77  10206     79]\n",
      " [   613    251    167    111   7019]]\n",
      "Validating..\n",
      "Validation loss:  0.4275024746145521\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9383734669763273\n",
      "\t average f1 :  0.7885595764787584\n",
      "\t f1 :  [0.62542831 0.97815599 0.70493685 0.82512409 0.80915263]\n",
      "\t confusion matrix :  [[ 1734   208    43    97   168]\n",
      " [  852 39943    49   202   118]\n",
      " [  149   117   614    55    72]\n",
      " [  320   160    14  2161    35]\n",
      " [  240    78    15    33  1609]]\n",
      "********************************************************************************\n",
      "Epoch #5\n",
      "Training..\n",
      "Training loss:  0.36000087636488454\n",
      "Training metrics:\n",
      "\t accuracy :  0.9829931803102036\n",
      "\t average f1 :  0.9253316965415934\n",
      "\t f1 :  [0.88895684 0.99628673 0.86835501 0.96664379 0.90641612]\n",
      "\t confusion matrix :  [[  8722    359    193    160    424]\n",
      " [   204 166617     61     49     44]\n",
      " [   219    236   3806     71    189]\n",
      " [   143    148     52  10563     44]\n",
      " [   477    141    133     62   7332]]\n",
      "Validating..\n",
      "Validation loss:  0.3614946220602308\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9405736869983294\n",
      "\t average f1 :  0.7933664163946267\n",
      "\t f1 :  [0.64269747 0.97908789 0.71072589 0.82918488 0.80513595]\n",
      "\t confusion matrix :  [[ 1725   199    57    92   177]\n",
      " [  708 40007    76   241   132]\n",
      " [  139   123   656    33    56]\n",
      " [  300   161    14  2182    33]\n",
      " [  246    69    36    25  1599]]\n",
      "********************************************************************************\n",
      "Epoch #6\n",
      "Training..\n",
      "Training loss:  0.298817644516627\n",
      "Training metrics:\n",
      "\t accuracy :  0.9871722561356048\n",
      "\t average f1 :  0.9429072494396644\n",
      "\t f1 :  [0.91126245 0.99741825 0.90071002 0.98151184 0.92363369]\n",
      "\t confusion matrix :  [[  8965    262    168     83    394]\n",
      " [   180 166510     49     24     33]\n",
      " [   168    169   3996     52    150]\n",
      " [    87     60     23  10777     28]\n",
      " [   404     85    102     49   7529]]\n",
      "Validating..\n",
      "Validation loss:  0.31047277791159494\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9423460864604979\n",
      "\t average f1 :  0.8038591933803405\n",
      "\t f1 :  [0.64549106 0.97930174 0.73556899 0.83775588 0.8211783 ]\n",
      "\t confusion matrix :  [[ 1768   219    48    83   132]\n",
      " [  768 40027    52   222    95]\n",
      " [  148   108   669    38    44]\n",
      " [  278   168     9  2210    25]\n",
      " [  266    60    34    33  1582]]\n",
      "********************************************************************************\n",
      "Epoch #7\n",
      "Training..\n",
      "Training loss:  0.2516651815838284\n",
      "Training metrics:\n",
      "\t accuracy :  0.9903401638731105\n",
      "\t average f1 :  0.9567811711367046\n",
      "\t f1 :  [0.93218788 0.99802183 0.92169621 0.98770156 0.94429838]\n",
      "\t confusion matrix :  [[  9169    208    156     58    297]\n",
      " [   140 166743     39     23     27]\n",
      " [   135    125   4108     29    119]\n",
      " [    53     47     13  10842     21]\n",
      " [   287     52     82     26   7722]]\n",
      "Validating..\n",
      "Validation loss:  0.2701441305024283\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9439962514769995\n",
      "\t average f1 :  0.8075512038513409\n",
      "\t f1 :  [0.66576297 0.97962281 0.73729267 0.83534884 0.81972873]\n",
      "\t confusion matrix :  [[ 1719   199    54   100   178]\n",
      " [  652 40022    82   262   146]\n",
      " [  104   115   689    39    60]\n",
      " [  240   158    13  2245    34]\n",
      " [  199    51    24    39  1662]]\n",
      "********************************************************************************\n",
      "Epoch #8\n",
      "Training..\n",
      "Training loss:  0.21338094826097842\n",
      "Training metrics:\n",
      "\t accuracy :  0.9928206358008963\n",
      "\t average f1 :  0.9679460255110282\n",
      "\t f1 :  [0.9474059  0.99855428 0.94375489 0.9930884  0.95692666]\n",
      "\t confusion matrix :  [[  9313    163    120     36    243]\n",
      " [   107 166458     35     10     28]\n",
      " [   104     82   4220     14     84]\n",
      " [    41     16      6  10920     11]\n",
      " [   220     41     58     18   7809]]\n",
      "Validating..\n",
      "Validation loss:  0.23710770905017853\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9464205679827242\n",
      "\t average f1 :  0.8116437202555608\n",
      "\t f1 :  [0.6955598  0.97886033 0.72344689 0.83911078 0.8212408 ]\n",
      "\t confusion matrix :  [[ 1637   331    74    81   127]\n",
      " [  420 40308   114   237    85]\n",
      " [   68   151   722    37    29]\n",
      " [  144   279    14  2227    26]\n",
      " [  188   124    65    36  1562]]\n",
      "********************************************************************************\n",
      "Epoch #9\n",
      "Training..\n",
      "Training loss:  0.18253600707760564\n",
      "Training metrics:\n",
      "\t accuracy :  0.9931153957524138\n",
      "\t average f1 :  0.9691103736262591\n",
      "\t f1 :  [0.94813236 0.9986511  0.94558351 0.99453253 0.95865237]\n",
      "\t confusion matrix :  [[  9341    150    131     24    228]\n",
      " [   118 166577     33     10     20]\n",
      " [   100     76   4266     13     78]\n",
      " [    31     12      6  10914      9]\n",
      " [   240     31     54     15   7825]]\n",
      "Validating..\n",
      "Validation loss:  0.2096507144825799\n",
      "Validation metrics:\n",
      "\t accuracy :  0.947948498553559\n",
      "\t average f1 :  0.8181998323959736\n",
      "\t f1 :  [0.69559722 0.97919798 0.74449339 0.84488068 0.82682989]\n",
      "\t confusion matrix :  [[ 1651   342    42    65   150]\n",
      " [  425 40388    63   182   106]\n",
      " [   89   162   676    35    45]\n",
      " [  169   294     8  2195    24]\n",
      " [  163   142    20    29  1621]]\n",
      "********************************************************************************\n",
      "Epoch #10\n",
      "Training..\n",
      "Training loss:  0.15666767734068412\n",
      "Training metrics:\n",
      "\t accuracy :  0.9945744049548448\n",
      "\t average f1 :  0.9760947248711469\n",
      "\t f1 :  [0.9590828  0.99891068 0.96059872 0.99492107 0.96696035]\n",
      "\t confusion matrix :  [[  9411    117     92     30    190]\n",
      " [    88 166894     30      6     23]\n",
      " [    75     59   4364      3     50]\n",
      " [    31     13      4  10872     10]\n",
      " [   180     28     45     14   7902]]\n",
      "Validating..\n",
      "Validation loss:  0.18707304980073655\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9502709530212281\n",
      "\t average f1 :  0.8210417184309993\n",
      "\t f1 :  [0.71372729 0.97958198 0.72946102 0.85289575 0.82954255]\n",
      "\t confusion matrix :  [[ 1552   412    68    63   155]\n",
      " [  256 40564    91   158    95]\n",
      " [   53   186   697    30    41]\n",
      " [  105   344     8  2209    24]\n",
      " [  133   149    40    30  1623]]\n",
      "********************************************************************************\n",
      "Epoch #11\n",
      "Training..\n",
      "Training loss:  0.13696781932203858\n",
      "Training metrics:\n",
      "\t accuracy :  0.9936876196378502\n",
      "\t average f1 :  0.9763843060683811\n",
      "\t f1 :  [0.9648507  0.9980183  0.96623492 0.98288775 0.96992986]\n",
      "\t confusion matrix :  [[  9484    127     76     21    155]\n",
      " [    80 166194     40    215     46]\n",
      " [    52     37   4364      6     53]\n",
      " [    25     87      4  10827      8]\n",
      " [   155     28     37     11   7951]]\n",
      "Validating..\n",
      "Validation loss:  0.18392122856208257\n",
      "Validation metrics:\n",
      "\t accuracy :  0.940349590514607\n",
      "\t average f1 :  0.7884407140665355\n",
      "\t f1 :  [0.72222222 0.97125427 0.67152398 0.74776632 0.82943677]\n",
      "\t confusion matrix :  [[ 1495   583    32    22   118]\n",
      " [  165 40917    37    13    32]\n",
      " [   53   357   553     4    40]\n",
      " [   60   957     3  1632    38]\n",
      " [  117   278    15     4  1561]]\n",
      "********************************************************************************\n",
      "Epoch #12\n",
      "Training..\n",
      "Training loss:  0.11907746504854273\n",
      "Training metrics:\n",
      "\t accuracy :  0.9944730417242912\n",
      "\t average f1 :  0.9778577888956146\n",
      "\t f1 :  [0.96427478 0.99843041 0.96442157 0.99038109 0.97178109]\n",
      "\t confusion matrix :  [[  9447    136     72     19    160]\n",
      " [    83 166661     34     25     18]\n",
      " [    45     91   4310      4     42]\n",
      " [    26    107      3  10811     16]\n",
      " [   159     30     27     10   7955]]\n",
      "Validating..\n",
      "Validation loss:  0.15152303448745183\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9524711730432303\n",
      "\t average f1 :  0.8270843889571748\n",
      "\t f1 :  [0.73232908 0.98034821 0.7311828  0.86016038 0.83140148]\n",
      "\t confusion matrix :  [[ 1580   405    73    66   126]\n",
      " [  216 40682    90   108    68]\n",
      " [   55   186   714    25    27]\n",
      " [   63   396    10  2199    22]\n",
      " [  151   162    59    25  1578]]\n",
      "********************************************************************************\n",
      "Epoch #13\n",
      "Training..\n",
      "Training loss:  0.1027858469773222\n",
      "Training metrics:\n",
      "\t accuracy :  0.9965921394678149\n",
      "\t average f1 :  0.9850935525695244\n",
      "\t f1 :  [0.97351061 0.99937102 0.97844113 0.99702803 0.97711698]\n",
      "\t confusion matrix :  [[  9592     71     54     14    141]\n",
      " [    50 166831     21      6     20]\n",
      " [    38     24   4425      4     30]\n",
      " [    17      6      4  10903      6]\n",
      " [   137     12     20      8   7985]]\n",
      "Validating..\n",
      "Validation loss:  0.14420260063239507\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9490893533797824\n",
      "\t average f1 :  0.8176946664503326\n",
      "\t f1 :  [0.70390365 0.97931567 0.73108265 0.85834671 0.81582465]\n",
      "\t confusion matrix :  [[ 1695   372    25    49   109]\n",
      " [  389 40599    36    69    71]\n",
      " [  127   191   628    20    41]\n",
      " [  104   422     6  2139    19]\n",
      " [  251   165    16    17  1526]]\n",
      "********************************************************************************\n",
      "Epoch #14\n",
      "Training..\n",
      "Training loss:  0.0897899529448262\n",
      "Training metrics:\n",
      "\t accuracy :  0.9965155750798722\n",
      "\t average f1 :  0.9843468891236317\n",
      "\t f1 :  [0.9733455  0.99939153 0.97529633 0.99735594 0.97634514]\n",
      "\t confusion matrix :  [[  9604     63     52     14    127]\n",
      " [    49 166711     25      3     18]\n",
      " [    51     27   4402      4     34]\n",
      " [    17      6      1  10939      7]\n",
      " [   153     12     29      6   7966]]\n",
      "Validating..\n",
      "Validation loss:  0.13168074722800935\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9524508006356192\n",
      "\t average f1 :  0.8293556590066966\n",
      "\t f1 :  [0.73792299 0.97977296 0.74822501 0.85428907 0.82656827]\n",
      "\t confusion matrix :  [[ 1581   442    42    62   123]\n",
      " [  182 40737    57   117    71]\n",
      " [   49   209   685    29    35]\n",
      " [   51   429     7  2181    22]\n",
      " [  172   175    33    27  1568]]\n",
      "********************************************************************************\n",
      "Epoch #15\n",
      "Training..\n",
      "Training loss:  0.07858213699526256\n",
      "Training metrics:\n",
      "\t accuracy :  0.9968529620061245\n",
      "\t average f1 :  0.987063937738524\n",
      "\t f1 :  [0.97419257 0.9993263  0.98490358 0.99753537 0.97936187]\n",
      "\t confusion matrix :  [[  9607    100     41      9    130]\n",
      " [    54 166875     12      6     19]\n",
      " [    26     19   4469      2     18]\n",
      " [    17      5      3  10928      7]\n",
      " [   132     10     16      5   7996]]\n",
      "Validating..\n",
      "Validation loss:  0.12417573268924441\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9535916554618424\n",
      "\t average f1 :  0.8320064068012412\n",
      "\t f1 :  [0.7376058  0.98010255 0.74454829 0.85906572 0.83870968]\n",
      "\t confusion matrix :  [[ 1525   464    68    65   128]\n",
      " [  139 40810    89    78    48]\n",
      " [   36   200   717    29    25]\n",
      " [   42   451     7  2170    20]\n",
      " [  143   188    38    20  1586]]\n",
      "************ Training Done! ************\n"
     ]
    }
   ],
   "source": [
    "## TODO: Re-run with unidirectional LSTMs\n",
    "train_val_loop_lstm(\n",
    "    {\n",
    "        \"bidirectional\": False,\n",
    "        \"batch_size\": 512,\n",
    "        \"d_emb\": 64,\n",
    "        \"d_hidden\": 128,\n",
    "        \"num_epochs\": 15,\n",
    "        \"learning_rate\": 0.005,\n",
    "        \"l2\": 1e-6,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8UChDyKaPBs"
   },
   "source": [
    "### Questions **(2 points)**\n",
    "\n",
    "(a) How does the final performance of LSTMs compare to FFNNs? Is it better? What is a possible explanation?\n",
    "\n",
    "(b) How does bidirectional LSTMs compare to unidirectional LSTMs? Why?\n",
    "\n",
    "**TODO: Please fill in your answer here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "\n",
    "**Performance Comparison**:\n",
    "LSTMs (Long Short-Term Memory networks) generally outperform FFNNs (Feedforward Neural Networks) on sequence-based tasks such as Natural Language Processing (NLP), time series prediction, and speech recognition.\n",
    "\n",
    "**Possible Explanation**:\n",
    "- **Sequential Data Handling**: LSTMs are specifically designed to handle sequential data and can capture temporal dependencies and patterns over time. They maintain a memory of previous inputs, which allows them to understand context and relationships in sequences.\n",
    "- **Vanishing Gradient Problem**: LSTMs mitigate the vanishing gradient problem through their gating mechanisms (input, forget, and output gates), allowing them to learn long-term dependencies more effectively than FFNNs.\n",
    "- **Contextual Understanding**: In tasks like NLP, understanding the context of a word within a sentence is crucial. LSTMs can maintain context over long sequences, whereas FFNNs treat each input independently and lack this capability.\n",
    "\n",
    "### (b)\n",
    "\n",
    "**Performance Comparison**:\n",
    "Bidirectional LSTMs (BiLSTMs) often outperform unidirectional LSTMs on tasks where understanding the context from both past and future inputs is beneficial.\n",
    "\n",
    "**Possible Explanation**:\n",
    "- **Context from Both Directions**: Bidirectional LSTMs process the input sequence in both forward and backward directions. This allows them to capture information from both past and future contexts, providing a more comprehensive understanding of the sequence.\n",
    "- **Enhanced Feature Representation**: By combining the outputs from both directions, BiLSTMs can create richer and more informative feature representations, which can lead to better performance on tasks like named entity recognition, machine translation, and sentiment analysis.\n",
    "- **Improved Accuracy**: In many NLP tasks, the meaning of a word can depend on both preceding and succeeding words. BiLSTMs can leverage this bidirectional context to improve accuracy and performance.\n",
    "\n",
    "**Example**:\n",
    "Consider the sentence \"The cat sat on the mat.\" To understand the word \"sat,\" it is helpful to know both the preceding context (\"The cat\") and the succeeding context (\"on the mat\"). A bidirectional LSTM can utilize information from both directions to better understand the word \"sat\" in this context."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
