{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6YTnpgbFdMI",
    "outputId": "e8a79660-2c2b-4a57-cf57-1cf069eb7c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 10 17:48:09 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.12              Driver Version: 550.90.12      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  |   00000000:1A:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             40W /  300W |       1MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           On  |   00000000:1C:00.0 Off |                    0 |\n",
      "| N/A   27C    P0             40W /  300W |       1MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-32GB           On  |   00000000:1D:00.0 Off |                    0 |\n",
      "| N/A   25C    P0             39W /  300W |       1MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-32GB           On  |   00000000:1E:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             41W /  300W |       1MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==2.2.0 torchtext==0.17.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install -U scikit-learn\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c62StNb2NvKk",
    "outputId": "03be5bda-0ee1-40d8-bdd2-38b3b9f6eb81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 2.2.0+rocm5.7\n",
      "Torchtext Version: 0.17.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "print(\"Torch Version:\", torch.__version__)\n",
    "print(\"Torchtext Version:\", torchtext.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EjRM4cCFRh-d"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.vocab import Vocab, vocab\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict, Optional, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yn1bIPjAN-9V"
   },
   "source": [
    "## Feedforward Neural Network (FFNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJOKIneRTrTH"
   },
   "source": [
    "### Data Loading\n",
    "\n",
    "We will use the same dataset for named entity recognition in Assignment #2. First download the data and take a look at the first 50 lines:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVt1a6nzWsiF"
   },
   "source": [
    "Each line corresponds to a word. Different sentences are separated by an additional line break. Take \"EU NNP I-NP ORG\" as an example. \"EU\" is a word. \"NNP\" and \"I-NP\" are tags for POS tagging and chunking, which we will ignore. \"ORG\" is the tag for NER, which is our prediction target. There are 5 possible values for the NER tag: ORG, PER, LOC, MISC, and O.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooQEJEafWCcd"
   },
   "source": [
    "First, we write a dataloader for loading the dataset into mini-batches used for training the model. See [torch.utils.data](https://pytorch.org/docs/stable/data.html) for how dataloaders work in PyTorch. In short, we typically need to do two things:\n",
    "\n",
    "1. Define a [map-style dataset](https://pytorch.org/docs/stable/data.html#map-style-datasets) by subclassing [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and overriding 3 methods: `__init__`, `__getitem__`, and `__len__`.\n",
    "1. Create a [Dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) by calling its constructor. We have to specify the dataset and a few hyperparameters such as batch size.\n",
    "\n",
    "Most of the work has been done by us. As a simple exercise, try to understand the code and implement `__len__`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WnNfOBUYJvVW"
   },
   "outputs": [],
   "source": [
    "# A sentence is a list of (word, tag) tuples.\n",
    "# For example, [(\"hello\", \"O\"), (\"world\", \"O\"), (\"!\", \"O\")]\n",
    "Sentence = List[Tuple[str, str]]\n",
    "\n",
    "\n",
    "def read_data_file(\n",
    "    datapath: str,\n",
    ") -> Tuple[List[Sentence], Dict[str, int], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Read and preprocess input data from the file `datapath`.\n",
    "    Example:\n",
    "    ```\n",
    "        sentences, word_cnt, tag_cnt = read_data_file(\"eng.train\")\n",
    "    ```\n",
    "    Return values:\n",
    "        `sentences`: a list of sentences, including words and NER tags\n",
    "        `word_cnt`: a Counter object, the number of occurrences of each word\n",
    "        `tag_cnt`: a Counter object, the number of occurences of each NER tag\n",
    "    \"\"\"\n",
    "    sentences: List[Sentence] = []\n",
    "    word_cnt: Dict[str, int] = Counter()\n",
    "    tag_cnt: Dict[str, int] = Counter()\n",
    "\n",
    "    for sentence_txt in open(datapath).read().split(\"\\n\\n\"):\n",
    "        if \"DOCSTART\" in sentence_txt:\n",
    "            # Ignore dummy sentences at the begining of each document.\n",
    "            continue\n",
    "        # Read a new sentence\n",
    "        sentences.append([])\n",
    "        for token in sentence_txt.split(\"\\n\"):\n",
    "            w, _, _, t = token.split()\n",
    "            # Replace all digits with \"0\" to reduce out-of-vocabulary words\n",
    "            w = re.sub(\"\\d\", \"0\", w)\n",
    "            word_cnt[w] += 1\n",
    "            tag_cnt[t] += 1\n",
    "            sentences[-1].append((w, t))\n",
    "\n",
    "    return sentences, word_cnt, tag_cnt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFVnIjA8KEe0"
   },
   "source": [
    "## Implement the `__len__` function below **(1 point)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9RGv1K0pP1bR"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FixedWindowDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each data example is a word, its NER tag (the target), and a fixed window centered around it (the input).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        datapath: str,\n",
    "        window_size: int,\n",
    "        words_vocab: Optional[Vocab] = None,\n",
    "        tags_vocab: Optional[Vocab] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the dataset by reading from datapath.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.examples = []\n",
    "        START = \"<START>\"\n",
    "        END = \"<END>\"\n",
    "        UNKNOWN = \"<UNKNOWN>\"\n",
    "\n",
    "        print(\"Loading data from %s\" % datapath)\n",
    "        sentences, word_cnt, tag_cnt = read_data_file(datapath)\n",
    "\n",
    "        # Extract windows\n",
    "        for sent in sentences:\n",
    "            words = [START for _ in range(window_size)]\n",
    "            tags = [None for _ in range(window_size)]\n",
    "            for w, t in sent:\n",
    "                words.append(w)\n",
    "                tags.append(t)\n",
    "            words.extend([END for _ in range(window_size)])\n",
    "            tags.extend([None for _ in range(window_size)])\n",
    "\n",
    "            for i, t in enumerate(tags[window_size:-window_size], start=window_size):\n",
    "                self.examples.append(\n",
    "                    {\n",
    "                        \"word\": words[i],\n",
    "                        \"tag\": t,\n",
    "                        \"context\": words[i - window_size : i + window_size + 1],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        print(\"%d examples loaded.\" % len(self.examples))\n",
    "\n",
    "        # set vocabs\n",
    "        if words_vocab is None:\n",
    "            words_vocab = vocab(word_cnt, specials=[START, END, UNKNOWN]) # automatically create a vocabulary from words in dataset\n",
    "            words_vocab.set_default_index(words_vocab[UNKNOWN])\n",
    "        self.words_vocab = words_vocab\n",
    "        self.unknown_idx = self.words_vocab[UNKNOWN]\n",
    "        self.start_idx = self.words_vocab[START]\n",
    "        self.end_idx = self.words_vocab[END]\n",
    "\n",
    "        if tags_vocab is None:\n",
    "            tags_vocab = vocab(tag_cnt, specials=[]) # automatically create tags vocabulary from tags in dataset\n",
    "        self.tags_vocab = tags_vocab\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get the idx'th example in the dataset.\n",
    "        Convert words and the tag to indexes.\n",
    "        \"\"\"\n",
    "        example = self.examples[idx]\n",
    "        word = example[\"word\"]\n",
    "        tag = example[\"tag\"]\n",
    "        context = example[\"context\"]\n",
    "        return {\n",
    "            \"word\": word,\n",
    "            \"word_idx\": self.words_vocab[word],\n",
    "            \"tag\": tag,\n",
    "            \"tag_idx\": self.tags_vocab[tag],\n",
    "            \"context\": context,\n",
    "            \"context_idxs\": torch.tensor(\n",
    "                [self.words_vocab[w] for w in context]\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Return the number of examples in the dataset.\n",
    "        \"\"\"\n",
    "        # TODO: Implement this method\n",
    "        return len(self.examples)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "F-aHcN5yJyoa"
   },
   "outputs": [],
   "source": [
    "def create_fixed_window_dataloaders(\n",
    "    batch_size: int, window_size: int, shuffle: bool = True\n",
    ") -> Tuple[DataLoader, DataLoader, Dict[str, Vocab]]:\n",
    "    \"\"\"\n",
    "    Create the dataloaders for training and validaiton.\n",
    "    \"\"\"\n",
    "    ds_train = FixedWindowDataset(\"eng.train\", window_size)\n",
    "    # Re-use the vocabulary of the training data\n",
    "    ds_val = FixedWindowDataset(\"eng.val\", window_size, words_vocab=ds_train.words_vocab, tags_vocab=ds_train.tags_vocab)\n",
    "    loader_train = DataLoader(\n",
    "        ds_train, batch_size, shuffle, drop_last=True, pin_memory=True\n",
    "    )\n",
    "    loader_val = DataLoader(ds_val, batch_size, pin_memory=True)\n",
    "    return loader_train, loader_val, ds_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODfPyQjPSmCv"
   },
   "source": [
    "Let's test our dataloader. Try to understand the output, as it will save your time later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "Zmt9c9svgzy8",
    "outputId": "cce6bfd1-8029-4220-84be-0c855807c25f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from eng.train\n",
      "203621 examples loaded.\n",
      "Loading data from eng.val\n",
      "49086 examples loaded.\n",
      "Iterating on the training data..\n",
      "{'word': ['EU', 'rejects', 'German'], 'word_idx': tensor([3, 4, 5]), 'tag': ['ORG', 'O', 'MISC'], 'tag_idx': tensor([0, 1, 2]), 'context': [('<START>', '<START>', 'EU'), ('<START>', 'EU', 'rejects'), ('EU', 'rejects', 'German'), ('rejects', 'German', 'call'), ('German', 'call', 'to')], 'context_idxs': tensor([[0, 0, 3, 4, 5],\n",
      "        [0, 3, 4, 5, 6],\n",
      "        [3, 4, 5, 6, 7]])}\n",
      "5\n",
      "torch.Size([3, 5])\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def check_fixed_window_dataloader() -> None:\n",
    "    loader_train, _, _ = create_fixed_window_dataloaders(\n",
    "        batch_size=3, window_size=2, shuffle=False\n",
    "    )\n",
    "    print(\"Iterating on the training data..\")\n",
    "    for i, data_batch in enumerate(loader_train):\n",
    "        if i == 0:\n",
    "            print(data_batch)\n",
    "            print(len(data_batch[\"context\"]))\n",
    "            print(data_batch[\"context_idxs\"].shape)\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "check_fixed_window_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hR_aJ-FincuN"
   },
   "source": [
    "### Implement the Model **(4 points)**\n",
    "\n",
    "Next, let's implement feedforward neural networks following the description of Problem 1 in Assignment #3.\n",
    "\n",
    "Models in PyTorch are subclasses of [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module). You have to override `__init__` for initializing the model and `forward` for calculating the forward pass. Checkout this [tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html#) if you are not sure how torch.nn.Module works.\n",
    "\n",
    "PyTorch provides a wide array of [neural network layers](https://pytorch.org/docs/stable/nn.html) as building blocks for your model. Here are some of them that may be relevant:\n",
    "\n",
    "- [nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding)\n",
    "- [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
    "- [torch.sigmoid](https://pytorch.org/docs/stable/generated/torch.sigmoid.html#torch.sigmoid) or [nn.Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid)\n",
    "\n",
    "Note a difference with Problem 3 of Assignment #2 is that we do not apply softmax when calculatinng $\\hat{y}^{(t)}$. Instead, we leave what softmax does to the loss function [F.cross_entropy](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.cross_entropy). For details, please see its difference with [F.nll_loss](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.nll_loss).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Hx0oMgVffSD1"
   },
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Feedforward Neural Networks for NER\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, words_vocab: Vocab, tags_vocab: Vocab, window_size: int, d_emb: int, d_hidden: int\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize a two-layer feedforward neural network with sigmoid activation.\n",
    "        Parameters:\n",
    "            `words_vocab`: vocabulary of words\n",
    "            `tags_vocab`: vocabulary of tags\n",
    "            `window_size`: size of the context window (w in Problem 3 of Assignment #2)\n",
    "            `d_emb`: dimension of word embeddings (D in Problem 3 of Assignment #2)\n",
    "            `d_hidden`: dimension of the hidden layer (H in Problem 3 of Assignment #2)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # TODO: Create the word embeddings (nn.Embedding),\n",
    "        self.words_vocab = words_vocab\n",
    "        self.tags_vocab = tags_vocab\n",
    "        self.window_size = window_size\n",
    "        self.d_emb = d_emb\n",
    "        self.d_hidden = d_hidden\n",
    "\n",
    "        self.embedding = nn.Embedding(len(words_vocab), d_emb)\n",
    "        self.hidden_layer = nn.Linear((2 * window_size + 1) * d_emb, d_hidden)\n",
    "        self.output_layer = nn.Linear(d_hidden, len(tags_vocab))\n",
    "\n",
    "    def forward(self, context_idxs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Given the word indexes in a context window, predict the logits of the NER tag.\n",
    "        Parameters:\n",
    "            `context_idxs`: a batch_size x (2 * window_size + 1) tensor\n",
    "                          context_idxs[i] contains word indexes in the window of the i'th data example.\n",
    "        Return values:\n",
    "            `logits`: a batch_size x 5 tensor (\\hat{y}^{(t)} in Problem 3 of Assignment #2, without softmax)\n",
    "                    logits[i][j] is the output score (before softmax) of the i'th example for tag j.\n",
    "        \"\"\"\n",
    "        # TODO: Implement the forward pass of the two-layer FFNN with sigmoid hidden layer.\n",
    "        #       Do not apply softmax, since we will use F.cross_entropy as the loss function.\n",
    "        \n",
    "                                                    # context_idxs: batch_size x (2 * window_size + 1) tensor\n",
    "        context_emb = self.embedding(context_idxs)  # batch_size x (2 * window_size + 1) x d_emb tensor\n",
    "        batch_size, _, _ = context_emb.size()\n",
    "        context_flat = context_emb.view(batch_size, -1)\n",
    "        hidden_output = torch.sigmoid(self.hidden_layer(context_flat))\n",
    "        logits = self.output_layer(hidden_output)   # batch_size x 5 tensor\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyZCvfOMR7YP"
   },
   "source": [
    "Optionally, let's do a simple sanity check of your implementation. In `check_ffnn`, we load a batch of data examples and pass it through the FFNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WLMGYSZ7KxzP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Some helper code\n",
    "def get_device() -> torch.device:\n",
    "    \"\"\"\n",
    "    Use GPU when it is available; use CPU otherwise.\n",
    "    \"\"\"\n",
    "    return torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "H7jikP_1fZP-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from eng.train\n",
      "203621 examples loaded.\n",
      "Loading data from eng.val\n",
      "49086 examples loaded.\n",
      "FFNN(\n",
      "  (words_vocab): Vocab()\n",
      "  (tags_vocab): Vocab()\n",
      "  (embedding): Embedding(20103, 64)\n",
      "  (hidden_layer): Linear(in_features=448, out_features=128, bias=True)\n",
      "  (output_layer): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n",
      "Input tensor shape: torch.Size([3, 7])\n",
      "Output tensor shape: torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "def check_ffnn() -> None:\n",
    "  # Hyperparameters\n",
    "  batch_size = 3\n",
    "  d_emb = 64\n",
    "  d_hidden = 128\n",
    "  window_size = 3\n",
    "  # Create the dataloaders and the model\n",
    "  loader_train, _, ds_train = create_fixed_window_dataloaders(batch_size, window_size)\n",
    "  model = FFNN(ds_train.words_vocab, ds_train.tags_vocab, window_size, d_emb, d_hidden)\n",
    "  device = get_device()\n",
    "  model.to(device)\n",
    "  print(model)\n",
    "  # Get the first batch\n",
    "  data_batch = next(iter(loader_train))\n",
    "  # Move data to GPU\n",
    "  context_idxs = data_batch[\"context_idxs\"].to(device, non_blocking=True)\n",
    "  tag_idx = data_batch[\"tag_idx\"].to(device, non_blocking=True)\n",
    "  # Calculate the model\n",
    "  print(\"Input tensor shape:\", context_idxs.size())\n",
    "  logits = model(context_idxs)\n",
    "  print(\"Output tensor shape:\", logits.size())\n",
    "\n",
    "check_ffnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PkRIOgeXIng0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from eng.train\n",
      "203621 examples loaded.\n"
     ]
    }
   ],
   "source": [
    "ds_train = FixedWindowDataset(\"eng.train\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0angAnEno9v"
   },
   "source": [
    "### Training and Validation **(4 points)**\n",
    "\n",
    "Having implemented the model, the next step is to implement functions for training and validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vWcKwiIMjekY"
   },
   "outputs": [],
   "source": [
    "def eval_metrics(ground_truth: List[int], predictions: List[int]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calculate various evaluation metrics such as accuracy and F1 score\n",
    "    Parameters:\n",
    "        `ground_truth`: the list of ground truth NER tags\n",
    "        `predictions`: the list of predicted NER tags\n",
    "    \"\"\"\n",
    "    f1_scores = f1_score(ground_truth, predictions, average=None)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(ground_truth, predictions),\n",
    "        \"average f1\": np.mean(f1_scores),\n",
    "        \"f1\": f1_scores,\n",
    "        \"confusion matrix\": confusion_matrix(ground_truth, predictions),\n",
    "    }\n",
    "\n",
    "\n",
    "def train_ffnn(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    silent: bool = False,  # whether to print the training loss\n",
    ") -> Tuple[float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Train the FFNN model.\n",
    "    Return values:\n",
    "        1. the average training loss\n",
    "        2. training metrics such as accuracy and F1 score\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "    losses = []\n",
    "    report_interval = 100\n",
    "\n",
    "    for i, data_batch in enumerate(loader):\n",
    "        context_idxs = data_batch[\"context_idxs\"].to(device, non_blocking=True)\n",
    "        tag_idx = data_batch[\"tag_idx\"].to(device, non_blocking=True)\n",
    "\n",
    "        # TODO:\n",
    "        # 1. Perform the forward pass to calculate the model's output. Save it to the variable \"logits\".\n",
    "        # 2. Calculate the loss using the output and the ground truth tags. Save it to the variable \"loss\".\n",
    "        # 3. Perform the backward pass to calculate the gradient.\n",
    "        # 4. Use the optimizer to update model parameters.\n",
    "        # Caveat: You may need to call optimizer.zero_grad(). Figure out what it does!\n",
    "        \n",
    "        logits = model(context_idxs)\n",
    "        loss = F.cross_entropy(logits, tag_idx)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        ground_truth.extend(tag_idx.tolist())\n",
    "        predictions.extend(logits.argmax(dim=-1).tolist())\n",
    "\n",
    "        if not silent and i > 0 and i % report_interval == 0:\n",
    "            print(\n",
    "                \"\\t[%06d/%06d] Loss: %f\"\n",
    "                % (i, len(loader), np.mean(losses[-report_interval:]))\n",
    "            )\n",
    "\n",
    "    return np.mean(losses), eval_metrics(ground_truth, predictions)\n",
    "\n",
    "\n",
    "def validate_ffnn(\n",
    "    model: nn.Module, loader: DataLoader, device: torch.device\n",
    ") -> Tuple[float, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Validate the FFNN model.\n",
    "    Return values:\n",
    "        1. the average validation loss\n",
    "        2. validation metrics such as accuracy and F1 score\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data_batch in loader:\n",
    "            context_idxs = data_batch[\"context_idxs\"].to(device, non_blocking=True)\n",
    "            tag_idx = data_batch[\"tag_idx\"].to(device, non_blocking=True)\n",
    "\n",
    "            # TODO: Similar to what you did in train_ffnn, but only step 1 and 2.\n",
    "\n",
    "            logits = model(context_idxs)\n",
    "            loss = F.cross_entropy(logits, tag_idx)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            ground_truth.extend(tag_idx.tolist())\n",
    "            predictions.extend(logits.argmax(dim=-1).tolist())\n",
    "\n",
    "    return np.mean(losses), eval_metrics(ground_truth, predictions)\n",
    "\n",
    "\n",
    "def train_val_loop_ffnn(hyperparams: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Train and validate the FFNN model for a number of epochs.\n",
    "    \"\"\"\n",
    "    print(\"Hyperparameters:\", hyperparams)\n",
    "    # Create the dataloaders\n",
    "    loader_train, loader_val, ds_train = create_fixed_window_dataloaders(\n",
    "        hyperparams[\"batch_size\"], hyperparams[\"window_size\"]\n",
    "    )\n",
    "    # Create the model\n",
    "    model = FFNN(\n",
    "        ds_train.words_vocab,\n",
    "        ds_train.tags_vocab,\n",
    "        hyperparams[\"window_size\"],\n",
    "        hyperparams[\"d_emb\"],\n",
    "        hyperparams[\"d_hidden\"],\n",
    "    )\n",
    "    device = get_device()\n",
    "    model.to(device)\n",
    "    print(model)\n",
    "    # Create the optimizer\n",
    "    optimizer = optim.RMSprop(\n",
    "        model.parameters(), hyperparams[\"learning_rate\"], weight_decay=hyperparams[\"l2\"]\n",
    "    )\n",
    "\n",
    "    # Train and validate\n",
    "    for i in range(hyperparams[\"num_epochs\"]):\n",
    "        print(\"*\" * 80 )\n",
    "        print(f\"Epoch #{i+1}\")\n",
    "\n",
    "        print(\"Training..\")\n",
    "        loss_train, metrics_train = train_ffnn(\n",
    "            model, loader_train, optimizer, device, silent=True\n",
    "        )\n",
    "        print(\"Training loss: \", loss_train)\n",
    "        print(\"Training metrics:\")\n",
    "        for k, v in metrics_train.items():\n",
    "            print(\"\\t\", k, \": \", v)\n",
    "\n",
    "        print(\"Validating..\")\n",
    "        loss_val, metrics_val = validate_ffnn(model, loader_val, device)\n",
    "        print(\"Validation loss: \", loss_val)\n",
    "        print(\"Validation metrics:\")\n",
    "        for k, v in metrics_val.items():\n",
    "            print(\"\\t\", k, \": \", v)\n",
    "\n",
    "    print(\"************ Training Done! ************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbuC7sYHX3Wl"
   },
   "source": [
    "We are ready to run experiments! Let's train the model for 5 epochs, with `window_size=2`. After each epoch, we perform validation and print the evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5ZTOFj9NXl65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: {'batch_size': 512, 'd_emb': 64, 'd_hidden': 128, 'window_size': 2, 'num_epochs': 5, 'learning_rate': 0.01, 'l2': 1e-06}\n",
      "Loading data from eng.train\n",
      "203621 examples loaded.\n",
      "Loading data from eng.val\n",
      "49086 examples loaded.\n",
      "FFNN(\n",
      "  (words_vocab): Vocab()\n",
      "  (tags_vocab): Vocab()\n",
      "  (embedding): Embedding(20103, 64)\n",
      "  (hidden_layer): Linear(in_features=320, out_features=128, bias=True)\n",
      "  (output_layer): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n",
      "********************************************************************************\n",
      "Epoch #1\n",
      "Training..\n",
      "Training loss:  0.18468522895080616\n",
      "Training metrics:\n",
      "\t accuracy :  0.9458979455289672\n",
      "\t average f1 :  0.8047429246415344\n",
      "\t f1 :  [0.75611224 0.97651615 0.65124167 0.83429429 0.80555028]\n",
      "\t confusion matrix :  [[  6912   2026    208    426    438]\n",
      " [   487 167411    557    549    289]\n",
      " [   252   1266   2688    141    239]\n",
      " [   297   1654     65   8899    183]\n",
      " [   325   1224    151    220   6357]]\n",
      "Validating..\n",
      "Validation loss:  0.13130161918040054\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9624129079574624\n",
      "\t average f1 :  0.8633187686213393\n",
      "\t f1 :  [0.79660628 0.98461909 0.78944534 0.87236581 0.87355732]\n",
      "\t confusion matrix :  [[ 1737   324    39    62    88]\n",
      " [  135 40874    48    57    50]\n",
      " [   36   189   733    10    39]\n",
      " [   96   347     9  2194    44]\n",
      " [  107   127    21    17  1703]]\n",
      "********************************************************************************\n",
      "Epoch #2\n",
      "Training..\n",
      "Training loss:  0.03480145464221987\n",
      "Training metrics:\n",
      "\t accuracy :  0.9903229297858942\n",
      "\t average f1 :  0.9612162863824011\n",
      "\t f1 :  [0.94546735 0.99683372 0.92388159 0.9826834  0.95721537]\n",
      "\t confusion matrix :  [[  9397    302    101     55    152]\n",
      " [   176 168905     77     62     66]\n",
      " [    96    201   4151     33     96]\n",
      " [    47     88     21  10924     29]\n",
      " [   155    101     59     50   7920]]\n",
      "Validating..\n",
      "Validation loss:  0.13908689403857957\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9621480666585177\n",
      "\t average f1 :  0.8634401943145281\n",
      "\t f1 :  [0.80121325 0.98440791 0.77360406 0.87667162 0.88130413]\n",
      "\t confusion matrix :  [[ 1717   289    46   103    95]\n",
      " [  143 40659   121   151    90]\n",
      " [   34   154   762    35    22]\n",
      " [   69   235    12  2360    14]\n",
      " [   73   105    22    45  1730]]\n",
      "********************************************************************************\n",
      "Epoch #3\n",
      "Training..\n",
      "Training loss:  0.02136483573371202\n",
      "Training metrics:\n",
      "\t accuracy :  0.9934469458438288\n",
      "\t average f1 :  0.9762608687004004\n",
      "\t f1 :  [0.96573897 0.99744054 0.95675082 0.98559337 0.97578064]\n",
      "\t confusion matrix :  [[  9612    208     47     42     92]\n",
      " [   135 168938     80     89     42]\n",
      " [    45    130   4358     11     42]\n",
      " [    35    102      7  10946     17]\n",
      " [    78     81     32     17   8078]]\n",
      "Validating..\n",
      "Validation loss:  0.15752019002078063\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9629222181477407\n",
      "\t average f1 :  0.8695915236771423\n",
      "\t f1 :  [0.81392668 0.98463367 0.80170576 0.87774295 0.86994857]\n",
      "\t confusion matrix :  [[ 1765   253    36    84   112]\n",
      " [  150 40593    62   202   157]\n",
      " [   38   156   752    32    29]\n",
      " [   73   199     4  2380    34]\n",
      " [   61    88    15    35  1776]]\n",
      "********************************************************************************\n",
      "Epoch #4\n",
      "Training..\n",
      "Training loss:  0.021698716463127012\n",
      "Training metrics:\n",
      "\t accuracy :  0.9932599968513854\n",
      "\t average f1 :  0.9773077780393233\n",
      "\t f1 :  [0.96981851 0.99706866 0.96123861 0.9815282  0.97688491]\n",
      "\t confusion matrix :  [[  9672    191     45     41     54]\n",
      " [   139 168880     68    118     80]\n",
      " [    41    128   4377     16     25]\n",
      " [    37    159      5  10893     16]\n",
      " [    54    110     25     18   8072]]\n",
      "Validating..\n",
      "Validation loss:  0.15512785361230877\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9641038177891863\n",
      "\t average f1 :  0.8701454735790758\n",
      "\t f1 :  [0.80953483 0.98477807 0.77666999 0.8895741  0.89017038]\n",
      "\t confusion matrix :  [[ 1749   304    51    67    79]\n",
      " [  133 40790   135    73    33]\n",
      " [   33   168   779    14    13]\n",
      " [   70   281    14  2308    17]\n",
      " [   86   134    20    37  1698]]\n",
      "********************************************************************************\n",
      "Epoch #5\n",
      "Training..\n",
      "Training loss:  0.018324557710286484\n",
      "Training metrics:\n",
      "\t accuracy :  0.994475165302267\n",
      "\t average f1 :  0.9806488540152944\n",
      "\t f1 :  [0.97417934 0.99780326 0.96759361 0.98422429 0.97944377]\n",
      "\t confusion matrix :  [[  9734    142     35     40     60]\n",
      " [   103 168970     68     80     54]\n",
      " [    31    109   4419     11     19]\n",
      " [    43    118      3  10918     25]\n",
      " [    62     70     20     30   8100]]\n",
      "Validating..\n",
      "Validation loss:  0.16801449952057132\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9655095139143544\n",
      "\t average f1 :  0.8764582231203321\n",
      "\t f1 :  [0.81881449 0.98509332 0.80485116 0.88384513 0.88968702]\n",
      "\t confusion matrix :  [[ 1706   339    27    71   107]\n",
      " [   80 40906    39    99    40]\n",
      " [   38   195   730    26    18]\n",
      " [   33   314     2  2317    24]\n",
      " [   60   132     9    40  1734]]\n",
      "************ Training Done! ************\n"
     ]
    }
   ],
   "source": [
    "train_val_loop_ffnn(\n",
    "    {\n",
    "        \"batch_size\": 512,\n",
    "        \"d_emb\": 64,\n",
    "        \"d_hidden\": 128,\n",
    "        \"window_size\": 2,\n",
    "        \"num_epochs\": 5,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"l2\": 1e-6,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h52XPGEg7JOu"
   },
   "source": [
    "Please re-run with `window_size=1`. How does the final performance change?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TvikQAmC2aW1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: {'batch_size': 512, 'd_emb': 64, 'd_hidden': 128, 'window_size': 1, 'num_epochs': 5, 'learning_rate': 0.01, 'l2': 1e-06}\n",
      "Loading data from eng.train\n",
      "203621 examples loaded.\n",
      "Loading data from eng.val\n",
      "49086 examples loaded.\n",
      "FFNN(\n",
      "  (words_vocab): Vocab()\n",
      "  (tags_vocab): Vocab()\n",
      "  (embedding): Embedding(20103, 64)\n",
      "  (hidden_layer): Linear(in_features=192, out_features=128, bias=True)\n",
      "  (output_layer): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n",
      "********************************************************************************\n",
      "Epoch #1\n",
      "Training..\n",
      "Training loss:  0.18148409958074915\n",
      "Training metrics:\n",
      "\t accuracy :  0.9460504565491183\n",
      "\t average f1 :  0.8094308803163545\n",
      "\t f1 :  [0.74749237 0.97720246 0.70214918 0.81485527 0.80545512]\n",
      "\t confusion matrix :  [[  6856   1967    227    465    490]\n",
      " [   512 167364    167    953    290]\n",
      " [   298   1074   2777    238    196]\n",
      " [   271   1666     61   8952    155]\n",
      " [   402   1180     95    259   6349]]\n",
      "Validating..\n",
      "Validation loss:  0.14976017992497268\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9562604408589007\n",
      "\t average f1 :  0.8450193476397372\n",
      "\t f1 :  [0.77687975 0.98056057 0.77759652 0.83803252 0.85202738]\n",
      "\t confusion matrix :  [[ 1586   439    43    60   122]\n",
      " [   64 40984    42    32    42]\n",
      " [   28   226   715    16    22]\n",
      " [   59   572     4  2036    19]\n",
      " [   96   208    28    25  1618]]\n",
      "********************************************************************************\n",
      "Epoch #2\n",
      "Training..\n",
      "Training loss:  0.04024061284987467\n",
      "Training metrics:\n",
      "\t accuracy :  0.9885321552267002\n",
      "\t average f1 :  0.9531429355083387\n",
      "\t f1 :  [0.92562317 0.99673389 0.91736367 0.98029668 0.94569728]\n",
      "\t confusion matrix :  [[  9172    327    120     78    308]\n",
      " [   206 168914     80     54     54]\n",
      " [   151    200   4113     33     78]\n",
      " [    62     92     25  10871     45]\n",
      " [   222     94     54     48   7863]]\n",
      "Validating..\n",
      "Validation loss:  0.1473618759676659\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9586440125494031\n",
      "\t average f1 :  0.8561435954901949\n",
      "\t f1 :  [0.78545619 0.98236539 0.80043502 0.84250857 0.86995281]\n",
      "\t confusion matrix :  [[ 1739   322    28    53   108]\n",
      " [  156 40833    56    75    44]\n",
      " [   42   183   736    29    17]\n",
      " [  129   460     1  2089    11]\n",
      " [  112   170    11    23  1659]]\n",
      "********************************************************************************\n",
      "Epoch #3\n",
      "Training..\n",
      "Training loss:  0.028645592130561094\n",
      "Training metrics:\n",
      "\t accuracy :  0.9915134996851386\n",
      "\t average f1 :  0.9687034907622074\n",
      "\t f1 :  [0.95061542 0.99700372 0.95018146 0.98234711 0.96336974]\n",
      "\t confusion matrix :  [[  9461    241     70     52    191]\n",
      " [   171 168869     81     95     58]\n",
      " [    66    142   4320     15     41]\n",
      " [    47    131      7  10907     19]\n",
      " [   145     96     31     26   7982]]\n",
      "Validating..\n",
      "Validation loss:  0.18116768172330922\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9590718331092368\n",
      "\t average f1 :  0.8601731925524054\n",
      "\t f1 :  [0.78423446 0.98098887 0.81039248 0.84954683 0.87570332]\n",
      "\t confusion matrix :  [[ 1552   480    32    53   133]\n",
      " [   65 40971    30    63    35]\n",
      " [   16   218   733    22    18]\n",
      " [   29   513     2  2109    37]\n",
      " [   46   184     5    28  1712]]\n",
      "********************************************************************************\n",
      "Epoch #4\n",
      "Training..\n",
      "Training loss:  0.02685336770562535\n",
      "Training metrics:\n",
      "\t accuracy :  0.9915922150503779\n",
      "\t average f1 :  0.9710740150590151\n",
      "\t f1 :  [0.9587774  0.99662095 0.95677043 0.97854659 0.9646547 ]\n",
      "\t confusion matrix :  [[  9536    224     53     41    156]\n",
      " [   156 168854     79    128     71]\n",
      " [    45    145   4349     12     34]\n",
      " [    31    204      6  10833     27]\n",
      " [   114    138     19     26   7983]]\n",
      "Validating..\n",
      "Validation loss:  0.15469743922100557\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9591736951472926\n",
      "\t average f1 :  0.8544903242695477\n",
      "\t f1 :  [0.797669   0.98299562 0.77240685 0.84855721 0.87082294]\n",
      "\t confusion matrix :  [[ 1711   282    62    61   134]\n",
      " [  128 40726   126    96    88]\n",
      " [   25   174   767    23    18]\n",
      " [   97   409     3  2132    49]\n",
      " [   79   106    21    23  1746]]\n",
      "********************************************************************************\n",
      "Epoch #5\n",
      "Training..\n",
      "Training loss:  0.02289300639961168\n",
      "Training metrics:\n",
      "\t accuracy :  0.9930238507556675\n",
      "\t average f1 :  0.9751270477624135\n",
      "\t f1 :  [0.9635469  0.99735813 0.96091348 0.98318229 0.97063444]\n",
      "\t confusion matrix :  [[  9595    194     52     38    132]\n",
      " [   125 168940     66     95     52]\n",
      " [    43    117   4376     13     35]\n",
      " [    43    140      6  10903     18]\n",
      " [    99    106     24     20   8032]]\n",
      "Validating..\n",
      "Validation loss:  0.1652590695496959\n",
      "Validation metrics:\n",
      "\t accuracy :  0.9593774192234038\n",
      "\t average f1 :  0.861439028534152\n",
      "\t f1 :  [0.79990747 0.98186585 0.80497029 0.84219067 0.87826087]\n",
      "\t confusion matrix :  [[ 1729   318    31    57   115]\n",
      " [  152 40825    55    67    65]\n",
      " [   45   181   745    20    16]\n",
      " [   81   510     1  2076    22]\n",
      " [   66   160    12    20  1717]]\n",
      "************ Training Done! ************\n"
     ]
    }
   ],
   "source": [
    "train_val_loop_ffnn(\n",
    "    {\n",
    "        \"batch_size\": 512,\n",
    "        \"d_emb\": 64,\n",
    "        \"d_hidden\": 128,\n",
    "        \"window_size\": 1,\n",
    "        \"num_epochs\": 5,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"l2\": 1e-6,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGgA0zExVtg9"
   },
   "source": [
    "### Question **(1 point)**\n",
    "\n",
    "If everything works as expected, you should see the loss decrease and the accuracy increase for both training and validation. The final accuracy can be pretty high; you should probably debug if it's below 92%. However, **is accuracy a good metric for this problem? Why?**. Hint: look at the F1 scores for different tags and the confusion matrix.\n",
    "\n",
    "**TODO: Please fill in your answer here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy might not be the best metric for Named Entity Recognition (NER) tasks. Here's why:\n",
    "\n",
    "1. **Imbalanced Classes**: NER datasets often have imbalanced classes, where some tags (like 'O' for non-entity tokens) are much more frequent than others (like specific entity tags). Accuracy can be misleading in such cases because a model that always predicts the majority class can still achieve high accuracy.\n",
    "\n",
    "2. **F1 Score**: The F1 score, which is the harmonic mean of precision and recall, is a better metric for NER tasks. It considers both false positives and false negatives, providing a more balanced evaluation of the model's performance on each tag.\n",
    "\n",
    "3. **Confusion Matrix**: The confusion matrix can help identify specific types of errors the model is making, such as confusing one entity type with another. This detailed insight is not captured by accuracy alone.\n",
    "\n",
    "In summary, while accuracy gives a general idea of performance, the F1 score and confusion matrix provide more detailed and meaningful insights for NER tasks.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
